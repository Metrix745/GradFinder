{
    "scholar_id": "H7El-ZkAAAAJ",
    "name": "\u202aTing-Zhu Huang\u202c - \u202aGoogle Scholar\u202c",
    "description": [
        "Recently, tensor ring (TR) approximation has received increasing attention in multi-dimensional image processing. In TR approximation, the key backbone is the shallow matrix factorizations, which approximate the circular unfolding of the multi-dimensional image. However, the shallow matrix factorization limits the standard TR approximation\u2019s ability to represent images with complex details and textures. To address this limitation, we propose a nonlinear hierarchical matrix factorization-based tensor ring (NHTR) approximation. Specifically, instead of the shallow matrix factorization, we introduce the nonlinear hierarchical matrix factorization in NHTR approximation to approximate circularly-modes unfoldings of an N-th order tensor. Benefiting from the powerful expressive capability of the nonlinear hierarchical matrix factorization, the proposed NHTR approximation can faithfully capture fine details of the clean\u00a0\u2026",
        "Attribute to its powerful representation ability, block term decomposition (BTD) has recently attracted many views of multi-dimensional data processing, e.g., hyperspectral image unmixing and blind source separation. However, the popular alternating least squares algorithm for rank-(L,\u00a0M,\u00a0N) BTD (BTD-ALS) suffers expensive time and space costs from Kronecker products and solving low-rank approximation subproblems, hindering the deployment of BTD for real applications, especially for large-scale data. In this paper, we propose a fast sketching-based Kronecker product-free algorithm for rank-(L,\u00a0M,\u00a0N) BTD (termed as KPF-BTD), which is suitable for real-world multi-dimensional data. Specifically, we first decompose the original optimization problem into several rank-(L,\u00a0M,\u00a0N) approximation subproblems, and then we design the bilateral sketching to obtain the approximate solutions of these subproblems instead of the exact solutions\u00a0\u2026",
        "Tensor ring (TR) decomposition has made remarkable achievements in numerous high-order data processing tasks. However, the current alternating least squares (ALS)-and singular value decomposition (SVD)-based algorithms for TR decomposition, ie, TR-ALS and TR-SVD, especially the former, are computationally expensive, making them unfriendly for large-scale data processing. This paper adopts three strategies to propose a novel fast TR decomposition algorithm:(1) Use a more efficient Lanczos bidiagonalization algorithm than SVD to generate the TR core tensors.(2) Exploit the hierarchical strategy to generate the TR core tensors in parallel.(3) Employ new reshaping and unfolding operations to reduce the dimensionality of the data used to generate TR core tensors. By incorporating these three strategies, we propose the TR-HLanczos algorithm for fast TR decomposition. This algorithm seamlessly\u00a0\u2026",
        "Hyperspectral image super-resolution (HSI SR) aims to combine the detailed spectral information of hyperspectral images with the spatial resolution of multispectral images, thus enhancing the ability to extract valuable insights across various applications. Recently, the tensor singular value decomposition ( t -SVD) has emerged as a powerful tool and has been introduced into the HSI SR field for exploring low-rank prior information. For  t -SVD, domain transform is crucial to acquiring more low-rank data characteristics. Nevertheless, previous efforts on domain transform have only involved the single transformed domain (i.e.,  single-domain ), while ignoring the potential pursuing the lower rankness in multiple successional transformed domains, termed  cross-domain  (CD). In this paper, we propose a novel cross-domain-based  t -SVD and define the corresponding tensor CD-rank based on a pivotal observation, i.e\u00a0\u2026",
        "Recently, tensor decompositions have attracted increasing attention and shown promising performance in processing multi-dimensional data. However, the existing tensor decompositions assume that the correlation along one mode is homogeneous and thus cannot characterize the multiple types of correlations (i.e., heterogeneous correlation) along the mode in real data. To address this issue, we propose a heterogeneous tensor product that allows us to explore this heterogeneous correlation, which can degenerate into the classic tensor products (e.g., mode product and tensor\u2013tensor product). Equipped with this heterogeneous tensor product, we develop a generalized tensor decomposition (GTD) framework for third-order tensors, which not only induces many novel tensor decompositions but also helps us to better understand the interrelationships between the new tensor decompositions and the existing\u00a0\u2026",
        "Many real-world images (e.g., hyperspectral images (HSIs) and color videos) are usually partially observed and contaminated by Poisson noise, which hinder their subsequent applications. Recently, the tensor singular value decomposition (t-SVD)-based model was suggested for image recovery with Poisson observation. However, the classic t-SVD usually fails to capture the complex nonlinear structure of real-world images. To address this problem, we suggest an attention-guided low-rank tensor factorization (AGLRTF)-based model for image recovery with Poisson observation. More concretely, we consider a self-attention network as the transform in the t-SVD framework, which can treat the frontal slices unequally, allowing us to enhance the low rankness of the transformed frontal slices. Also, the self-attention block is learned unsupervised from the given data. Extensive experiments on HSIs demonstrate that our\u00a0\u2026",
        "Tensor decomposition-based models have received increasing attention in hyperspectral image (HSI) denoising. However, tensor decompositions (e.g., Tucker decomposition and tensor singular value decomposition) in these HSI denoising models ignore exploiting the multiple components of the HSI, resulting in unsatisfactory denoising performance. To fully exploit the multiple components of the HSI, we develop a sparsity regularized rank-(L,M,N) block term decomposition (SR-BTD). In SR-BTD, the clean HSI is decomposed as the sum of multiple components, where each component is a sparse core tensor multiplied by matrices along each mode. The sparse regularization on each core tensor can benefit determining the low-rankness of each component with the unknown rank-(L,M,N) in the real world, leading to more accurately exploiting each component. Equipped with SR-BTD, we establish the HSI\u00a0\u2026",
        "In the context of Earth observation, change detection boils down to comparing images acquired at different times by sensors of possibly different spatial and/or spectral resolutions or different modalities (e.g., optical or radar). Even when considering only optical images, this task has proven to be challenging as soon as the sensors differ by their spatial and/or spectral resolutions. This paper proposes a novel unsupervised change detection method dedicated to images acquired by such so-called heterogeneous optical sensors. It capitalizes on recent advances which formulate the change detection task into a robust fusion framework. Adopting this formulation, the work reported in this paper shows that any off-the-shelf network trained beforehand to fuse optical images of different spatial and/or spectral resolutions can be easily complemented with a network of the same architecture and embedded into an adversarial\u00a0\u2026",
        "Pansharpening involves the spatial super-resolution of a low-resolution multispectral (LR-MS) image by leveraging a simultaneously acquired panchromatic (PAN) image, aiming to generate a high-resolution multispectral (HR-MS) image. Such an inverse problem mainly requires more accurately establishing the relation between the underlying HR-MS image and the PAN image. Because of the high redundancy of framelet transform, the framelet-based sparse error reconstruction has recently been well-investigated and achieved promising results. Nevertheless, previous works ignore the negative impact of the low-pass filter within the framelet, which experimentally distinguishes the coefficient similarity and reduces the error sparsity, thereby leading to limited numerical performance and high hyperparameter sensitivity. In this paper, we propose an improved pansharpening model via semi-framelet-guided sparse\u00a0\u2026",
        "Recently, fully-connected tensor network (FCTN) decomposition, which factorizes the target tensor into a series of interconnected factor tensors, has drawn growing focus on multi-dimensional visual data processing. However, the lack of clear physical interpretation for the factor tensors hinders us from introducing handcrafted regularizers to deeply explore the potential of FCTN decomposition. To tackle this issue, we suggest a unimode hierarchical nonlinear (UHN) decomposition for each factor tensor, which can adaptively capture the complex nonlinear structure and implicitly regularize factor tensors. With this UHN decomposition of the factor tensors, we naturally propose a nested fully-connected tensor network (N-FCTN) decomposition. Attributed to the adaptive and implicit regularization inherent in UHN decomposition of factor tensors, the proposed N-FCTN decomposition is expected to perform favorably\u00a0\u2026",
        "Recently, minimizing the tensor tubal rank based on the tensor singular value decomposition (t-SVD) has attracted significant attention in the tensor completion task. The widely-used solutions of tensor-tubal-rank minimization rely upon various convex and nonconvex surrogates of the tensor rank. However, these tensor rank surrogates usually lead to inaccurate descriptions of the tensor rank. To mitigate the limitation, we propose an innovative l0 minimization framework with guaranteed convergence to provide a novel paradigm for minimization of the tensor rank. To demonstrate the effectiveness of our framework, we develop a new tensor completion model employing a tensor adaptive sparsity-deduced rank (TASR). Subsequently, we formulate an algorithm rooted in the proposed l0 minimization framework to address this model effectively. Experimental results on multi-dimensional image data demonstrate that\u00a0\u2026",
        "Hyperspectral image (HSI) and multispectral image (MSI) fusion, denoted as HSI-MSI fusion, involves merging a pair of HSI and MSI to generate a high spatial resolution HSI (HR-HSI). The primary challenge in HSI-MSI fusion is to find the best way to extract 1-D spectral features and 2-D spatial features from HSI and MSI and harmoniously combine them. In recent times, coupled tensor decomposition (CTD)-based methods have shown promising performance in the fusion task. However, the tensor decompositions (TDs) used by these CTD-based methods face difficulties in extracting complex features and capturing 2-D spatial features, resulting in suboptimal fusion results. To address these issues, we introduce a novel method called coupled tensor double-factor (CTDF) decomposition. Specifically, we propose a tensor double-factor (TDF) decomposition, representing a third-order HR-HSI as a fourth-order spatial\u00a0\u2026",
        "Recently, the tensor nuclear norm (TNN)-based tensor robust principle component analysis (TRPCA) has achieved impressive performance in multidimensional data processing. The underlying assumption in TNN is the low-rankness of frontal slices of the tensor in the transformed domain (e.g., Fourier domain). However, the low-rankness assumption is usually violative for real-world multidimensional data (e.g., video and image) due to their intrinsically nonlinear structure. How to effectively and efficiently exploit the intrinsic structure of multidimensional data remains a challenge. In this article, we first suggest a kernelized TNN (KTNN) by leveraging the nonlinear kernel mapping in the transform domain, which faithfully captures the intrinsic structure (i.e., implicit low-rankness) of multidimensional data and is computed at a lower cost by introducing kernel trick. Armed with KTNN, we propose a tensor robust kernel\u00a0\u2026",
        "Tensor network (TN) representation is a powerful technique for computer vision and machine learning. TN structure search (TN-SS) aims to search for a customized structure to achieve a compact representation which is a challenging NP-hard problem. Recent\" sampling-evaluation\"-based methods require sampling an extensive collection of structures and evaluating them one by one resulting in prohibitively high computational costs. To address this issue we propose a novel TN paradigm named SVD-inspired TN decomposition (SVDinsTN) which allows us to efficiently solve the TN-SS problem from a regularized modeling perspective eliminating the repeated structure evaluations. To be specific by inserting a diagonal factor for each edge of the fully-connected TN SVDinsTN allows us to calculate TN cores and diagonal factors simultaneously with the factor sparsity revealing a compact TN structure. In theory we prove a convergence guarantee for the proposed method. Experimental results demonstrate that the proposed method achieves approximately 100 1000 times acceleration compared to the state-of-the-art TN-SS methods while maintaining a comparable level of representation ability.",
        "The fully-connected tensor network (FCTN) decomposition is an emerging method for processing and analyzing higher-order tensors. For an Nth-order tensor, the standard deterministic algorithms, such as alternating least squares (FCTN-ALS) algorithm, need to store large coefficient matrices formed by contracting  FCTN factor tensors. The memory cost of coefficient matrices grows exponentially with the size of the original tensor, which makes the algorithms memory-prohibitive for handling large-scale tensors. To enable FCTN decomposition to handle large-scale tensors effectively, we propose a stochastic gradient descent (FCTN-SGD) algorithm without sacrificing accuracy. The memory cost of FCTN-SGD algorithm grows linearly with the size of the original tensor and is significantly lower than that of the FCTN-ALS algorithm. The success of the FCTN-SGD algorithm lies in the suggested factor sampling\u00a0\u2026",
        "With a known large spectral library, sparse hyperspectral unmixing has been taken as a hotspot in academia all these years. Its fundamental task is to estimate the abundance fractions of the spectral signatures in mixed pixels. Typically, the sparse and low-rank properties of the abundance matrix have been exploited simultaneously in the literature. Many studies only consider the low-rank property of the entire abundance matrix, however, pay less attention to the property of each abundance map. In this paper, we propose a new way to describe the low-rank prior. Firstly, an abundance cube is obtained by concatenating the abundance maps along the third dimension. We construct a lower-dimensional projection subspace of the abundance cube using a projection matrix, and the low-rankness of the abundance matrix is preserved during the projection process. Secondly, we consider the low-rank property by directly\u00a0\u2026",
        "The method of moments discretization of boundary integral equations typically leads to dense linear systems. When a single operator is used for multiple excitations, these systems have the same coefficient matrix and multiple right-hand sides (RHSs). Direct solution methods are computationally attractive to use for the solution because they require one-round forward/backward substitution for each RHS, whereas the iterative solution necessitates a full-round iteration for each separate vector. However, direct methods become impractical to use even on modern parallel computers when the dimension    is large, due to their    memory and    computational complexity. In this article, we present experiments with a block iterative Krylov subspace method that solves the entire set of systems at once. The proposed method performs a block size reduction during the construction of the Krylov subspace and\u00a0\u2026",
        "Multi-dimensional data are inevitably corrupted, which hinders subsequent applications (e.g., image segmentation and classification). Recently, due to the powerful ability to characterize the correlation between any two modes of tensors, fully-connected tensor network (FCTN) decomposition has received increasing attention in multi-dimensional data recovery. However, the expressive power of FCTN decomposition in the original pixel domain has yet to be fully leveraged, which can not provide satisfactory results in the recovery of details and textures, especially for low-sampling rates or heavy noise scenarios. In this work, we suggest a feature-based FCTN decomposition model (termed as F-FCTN) for multi-dimensional data recovery, which can faithfully capture the relationship between the spatial-temporal/spectral-feature modes. Compared with the original FCTN decomposition, F-FCTN can more effectively\u00a0\u2026",
        "Pansharpening refers to the super resolution of a low-resolution multispectral (LR-MS) image in virtue of an aligned panchromatic (PAN) image. Such an inverse problem mainly requires a proper use of the spatial information from the auxiliary PAN image. In this paper, we suggest a nonconvex regularization model for pansharpening via framelet sparse reconstruction, called NC-FSRM, which investigates the coefficient similarity among the underlying high-resolution MS (HR-MS) and PAN images on the framelet domain, then characterizes the strong statistical sparsity of their error using  norm. Compared with previous methods, NC-FSRM can more precisely and concisely establish the relation between the underlying HR-MS and PAN images. In particular, the piece-wise smoothness prior of the former can simultaneously be captured without adding additional regularizers. For solving the suggested nonconvex\u00a0\u2026",
        "Recently, deep learning has been widely applied in the field of blind hyperspectral unmixing (HU), which aims to simultaneously estimate constitutive endmembers and their abundances in hyperspectral images (HSIs). Generally, the HU process based on deep-learning methods consists of two parts: an encoder and a decoder. In many networks, the decoder stage uses the extracted semantic information of the HSI by the encoder, without direct access to the manifold structure of the HSI. To address this limitation and simultaneously capture both the semantic information and manifold structure of the HSI, in this letter, we propose a dual-channel enhanced decoder network (DED-Net) for the HU problem. Specifically, DED-Net redesigns a decoder by adding a dual-channel graph regularizer that establishes a physically meaningful immediate connection between the abundance and the HSI, effectively integrating both\u00a0\u2026"
    ],
    "title": [
        "\u202aNonlinear Hierarchical Matrix Factorization-Based Tensor Ring Approximation for Multi-dimensional Image Recovery\u202c",
        "\u202aA Fast Algorithm for Rank-(L, M, N) Block Term Decomposition of Multi-Dimensional Data\u202c",
        "\u202aA fast Lanczos-based hierarchical algorithm for tensor ring decomposition\u202c",
        "\u202aCroDoSR: Tensor Cross-Domain Rank for Hyperspectral Image Super-Resolution\u202c",
        "\u202aThe Generalized Tensor Decomposition with Heterogeneous Tensor Product for Third-Order Tensors\u202c",
        "\u202aAttention Guided Low-Rank Tensor Factorization for Image Recovery with Poisson Observation\u202c",
        "\u202aSparsity Regularized Rank-(L, M, N) Block Term Decomposition for Hyperspectral Image Mixed Noise Removal\u202c",
        "\u202aCD-GAN: A robust fusion-based generative adversarial network for unsupervised remote sensing change detection with heterogeneous sensors\u202c",
        "\u202aPansharpening via semi-framelet-guided sparse reconstruction\u202c",
        "\u202aNested Fully-Connected Tensor Network Decomposition for Multi-Dimensional Visual Data Recovery\u202c",
        "\u202aA novel $\\ell_ {0} $ minimization framework of tensor tubal rank and its multi-dimensional image completion application\u202c",
        "\u202aA Coupled Tensor Double-Factor Method for Hyperspectral and Multispectral Image Fusion\u202c",
        "\u202aTensor Robust Kernel PCA for Multidimensional Data\u202c",
        "\u202aSVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from Regularized Modeling Perspective\u202c",
        "\u202aProvable stochastic algorithm for large-scale fully-connected tensor network decomposition\u202c",
        "\u202aProjection subspace based low-rank representation for sparse hyperspectral unmixing\u202c",
        "\u202aFast Iterative Solution of Multiple Right-Hand Sides MoM Linear Systems on CPUs and GPUs Computers\u202c",
        "\u202aMulti-dimensional data recovery via feature-based fully-connected tensor network decomposition\u202c",
        "\u202aA framelet sparse reconstruction method for pansharpening with guaranteed convergence\u202c",
        "\u202aDual-Channel Enhanced Decoder Network for Blind Hyperspectral Unmixing\u202c"
    ]
}