{
    "scholar_id": "ktn2QM4AAAAJ",
    "name": "\u202aKostas Kalpakis\u202c - \u202aGoogle Scholar\u202c",
    "description": [
        "Determination of prognosis in the triage process after traumatic brain injury (TBI) is difficult to achieve. Current severity measures like the Trauma and injury severity score (TRISS) and revised trauma score (RTS) rely on additional information from the Glasgow Coma Scale (GCS) and the Injury Severity Score (ISS) which may be inaccurate or delayed, limiting their usefulness in the rapid triage setting. We hypothesized that machine learning based estimations of GCS and ISS obtained through modeling of continuous vital sign features could be used to rapidly derive an automated RTS and TRISS. We derived variables from electrocardiograms (ECG), photoplethysmography (PPG), and blood pressure using continuous data obtained in the first 15\u00a0min of admission to build machine learning models of GCS and ISS (ML-GCS and ML-ISS). We compared the TRISS and RTS using ML-ISS and ML-GCS and its value\u00a0\u2026",
        "Classification and regression algorithms based on k-nearest neighbors (kNN) are often ranked among the top-10 Machine learning algorithms, due to their performance, flexibility, interpretability, non-parametric nature, and computational efficiency. Nevertheless, in existing kNN algorithms, the kNN radius, which plays a major role in the quality of kNN estimates, is independent of any weights associated with the training samples in a kNN-neighborhood. This omission, besides limiting the performance and flexibility of kNN, causes difficulties in correcting for covariate shift (e.g., selection bias) in the training data, taking advantage of unlabeled data, domain adaptation and transfer learning. We propose a new weighted kNN algorithm that, given training samples, each associated with two weights, called consensus and relevance (which may depend on the query on hand as well), and a request for an estimate of the\u00a0\u2026",
        " Tumor development can be indirectly evaluated using features of the tumor microenvironment (TME), such as hemoglobin saturation (HbSat), blood vessel dilation, and formation of new vessels. High values of HbSat and other features of the TME could indicate high metabolic activity and could precede the formation of angiogenic tumors; therefore, changes in HbSat profile can be used as a biomarker for tumor progression. One methodology to evaluate HbSat profile over time, and correlate it with tumor development in vivo in a preclinical model, is through a dorsal skin-fold window chamber. In this chapter, we provide a detailed description of this methodology to evaluate hemoglobin saturation profile and to predict tumor development. We will cover the surgical preparation of the mouse, the installation/maintenance of the dorsal window chamber, and the imaging processing and evaluation to the HbSat\u00a0\u2026",
        "A method is provided for predicting that a caregiver will order a blood transfusion during a treatment. The method includes obtaining, on a processor, first data that indicates values for one or more parameters of a characteristic of a peak of a Fourier transform of a continuous photoplethysmographic (PPG) waveform or a continuous electrocardiogram (ECG) waveform or both collected during the treatment. The method further includes applying, on the processor, coefficients to the values for the one or more parameters. The method further includes determining, on the processor, second data that indicates a prediction that the caregiver will order the blood transfusion during the treatment based on applying the coefficients to the values. The method further includes presenting on a display device output data based on the second data. An apparatus is also provided for predicting that the caregiver will order the blood\u00a0\u2026",
        "Axiom based inference provides a  clear and consistent way of reasoning to add more information to a knowledge graph.  However, constructing a set of axioms is expensive and requires domain expertise, time, and money.  It is also difficult to reuse or adapt a set of axioms to a knowledge graph in a new domain or even in the same domain but using a slightly different representation approach. This work makes three main contributions,  it (1) provides a family of representation learning algorithms and an extensive analysis on eight datasets; (2) yields better results than existing tensor and neural models; and (3) includes a provably convergent factorization algorithm.",
        "We present a family of novel methods for embedding knowledge graphs into real-valued tensors. These tensor-based embeddings capture the ordered relations that are typical in the knowledge graphs represented by semantic web languages like RDF. Unlike many previous models, our methods can easily use prior background knowledge provided by users or extracted automatically from existing knowledge graphs. In addition to providing more robust methods for knowledge graph embedding, we provide a provably-convergent, linear tensor factorization algorithm. We demonstrate the efficacy of our models for the task of predicting new facts across eight different knowledge graphs, achieving between 5% and 50% relative improvement over existing state-of-the-art knowledge graph embedding techniques. Our empirical evaluation shows that all of the tensor decomposition models perform well when the average\u00a0\u2026",
        "Identification of Circulating Tumor Cells (CTCs) has shown promising clinical applications, but since CTCs are found in very low concentration in blood large sample volumes are needed for meaningful enumeration. This issue impedes the analysis of CTCs using standard flow cytometry due to its low throughput. To address this issue, a high throughput microfluidic cytometer was recently developed using a wide field flow-flow cell instead of the conventional narrow hydrodynamic focusing cells (used in traditional flow cytometry) enabling analysis of large volumes at lower flow rate. This wide-field flow cytometer adopts a technique known as \u201cstreak photography\u201d where exposure times and flow velocities are set such that the particles are imaged as short \u201cstreaks\u201d. Since streaks are imaged with large number of pixels, they are easily distinguished from the noise which appears as \u201cspeckles\u201d increasing the detection capabilities of the device, making it more suitable for analysis using current low sensitivity, high noise webcams or mobile phone cameras. The non-stationary nature of the high noisy background found in streak cytometry introduces additional challenges for automated cell counting methods using traditional cell detection techniques such TLC, CellProfiler, CellTracker and other tools based in traditional edge detection (eg, Canny based filters) or manual thresholding. In order to address this issue, we developed a new automated enumeration approach that does not rely on edge detection or manual thresholding of individual cells, rather is based in image quantizing, morphological operations, 2D order-statistic filtering and decisions rules\u00a0\u2026",
        "Streak mode imaging flow cytometry for rare cell detection involves imaging moving fluorescently labeled cells in the video mode with a CCD camera. The path of the moving cells results in a \u201cstreak\u201d, whose length is proportional to the exposure time. The dynamic imaging conditions introduce detection challenges (e.g., images with high signal-to-noise ratio (SNR) backgrounds), especially for enumerating cells using low resolution webcams or smartphone cameras suitable for point of care testing (POCT). To overcome the imaging challenges, a new approach called a \u201ccomputational biosensor\u201d was developed. It involves combining biosensing hardware with computational algorithms to \u201ccomputationally transduce\u201d measureable signals from events captured by the hardware. The computational biosensor quantifies potential cells based on the streak intensity, length and relative location of the streaks in consecutive\u00a0\u2026",
        "Multi-relational data, like knowledge graphs, are generated from multiple data sources by extracting entities and their relationships. We often want to include inferred, implicit or likely relationships that are not explicitly stated, which can be viewed as link-prediction in a graph. Tensor decomposition models have been shown to produce state-of-the-art results in link-prediction tasks. We describe a simple but novel extension to an existing tensor decomposition model to predict missing links using similarity among tensor slices, as opposed to an existing tensor decomposition models which assumes each slice to contribute equally in predicting links. Our extended model performs better than the original tensor decomposition and the non-negative tensor decomposition variant of it in an evaluation on several datasets.",
        "Multi-relational data, like knowledge graphs, are generated from multiple data sources by extracting entities and their relationships. We often want to include inferred, implicit or likely relationships that are not explicitly stated, which can be viewed as link-prediction in a graph. Tensor decomposition models have been shown to produce state-of-the-art results in link-prediction tasks. We describe a simple but novel extension to an existing tensor decomposition model to predict missing links using similarity among tensor slices, as opposed to an existing tensor decomposition models which assumes each slice to contribute equally in predicting links. Our extended model performs better than the original tensor decomposition and the non-negative tensor decomposition variant of it in an evaluation on several datasets.",
        "Intelligent transportation systems can be built by developing models that learn from the collected transport data. Data collection and implementation of such systems is often costly, and few countries have support for such systems in their transportation budgets. In places where maintaining currency and accuracy of information is difficult, many problems arise. For instance, in Chennai, India, real time bus transit data is not maintained, there is no proper communication about the bus schedules, bus stops are not regularly updated and inconsistent information about bus stops is observed in the transport authority's website. We are interested in developing models for identifying bus stops from trajectories for situations where accurate and current information is not available and traffic conditions are challenging, such as Chennai, India. We develop a simple yet easily accessible Android mobile application (App) to collect\u00a0\u2026",
        "BACKGROUNDSecondary insults such as hypotension, hypoxia, cerebral hypoperfusion, and intracranial hypertension are associated with poor outcome following severe traumatic brain injury (TBI). Preventing and minimizing the effect of secondary insults are essential in the management of severe TBI. At present, clinicians have no way to predict the development of these events, limiting their ability to plan appropriate timing of interventions. We hypothesized that processing continuous vital signs (VS) data using machine learning methods could predict the development of future intracranial hypertension.METHODSContinuous VS including intracranial pressure (ICP), heart rate, systolic blood pressure, and mean arterial pressure data were collected from adult patients admitted to a single Level I trauma center requiring an ICP monitor. We tested the ability of Nearest Neighbor Regression (NNR) to predict changes\u00a0\u2026",
        "Permutation entropy is computationally efficient, robust to outliers, and effective to measure complexity of time series. We used this technique to quantify the complexity of continuous vital signs recorded from patients with traumatic brain injury (TBI). Using permutation entropy calculated from early vital signs (initial 10\u201320% of patient hospital stay time), we built classifiers to predict in-hospital mortality and mobility, measured by 3-month Extended Glasgow Outcome Score (GOSE). Sixty patients with severe TBI produced a skewed dataset that we evaluated for accuracy, sensitivity and specificity. The overall prediction accuracy achieved 91.67% for mortality, and 76.67% for 3-month GOSE in testing datasets, using the leave-one-out cross validation. We also applied Receiver Operating Characteristic analysis to compare classifiers built from different learning methods. Those results support the applicability of\u00a0\u2026",
        "METHODSWe compared self-reported confidence of participants (n= 523) with surgical tasks (n= 47) at baseline and directly after ASSET training to examine the effect of training. Median pre-and post-training self-reported confidence scores were assessed by Wilcoxon matched pairs test, directional change by Freeman-Halton contingency tests, and relative improvement for specific procedures using utility values assigned for each possible combination of pre-and post-training confidence levels.RESULTSAll surgeons recorded improved confidence in all five anatomic body regions after ASSET training (p< 0.0001). Following the course, surgeons reported a high confidence level in 78% of the 47 procedures. The body region most improved by ASSET training was the upper limb, with 49% of surgeons improving from low to high confidence (Freeman-Halton 1x3 p= 0.017). Residents/fellows achieved the greatest\u00a0\u2026",
        "Features of the tumor microenvironment (TME), such as hemoglobin saturation (HbSat), can provide valuable information on early development and progression of tumors. HbSat correlates with high metabolism and precedes the formation of angiogenic tumors; therefore, changes in HbSat profile can be used as a biomarker for early cancer detection. In this project, we develop a methodology to evaluate HbSat for forecasting early tumor development in a mouse model. We built a delta () cumulative feature that includes spatial and temporal distribution of HbSat for classifying tumor/normal areas. Using a two-class (normal and tumor) logistic regression, the  feature successfully forecasts tumor areas in two window chamber mice ( and 0.85). To assess the performance of the logistic regression-based classifier utilizing the  feature of each region, we conduct a 10-fold cross-validation analysis (AUC of the\u00a0\u2026",
        "Road traffic sensors provide rich multivariable datastreams about the current traffic conditions. Occasionally, there are unusual traffic events (such as accidents, jams, and severe weather) that disrupt the expected road traffic conditions. Detecting the occurrence of such events in an online and real-time manner is useful to drivers in planning their routes and in the management of the transportation infrastructure. We propose a new method for detecting traffic events that impact road traffic conditions by extending the Bayesian robust principal component analysis (RPCA) approach. Our method couples multiple traffic datastreams so that they share a certain sparse structure. This sparse structure is used to localize traffic events in space and time. The traffic datastreams are measurements of different physical quantities (e.g., traffic flow and road occupancy) by different nearby sensors. Our proposed method processes\u00a0\u2026",
        "An encryption relation  with decryption function  is {\\it``group-homomorphic''} if, for any suitable plaintexts  and , . It is {\\it``ring-homomorphic''} if furthermore ; it is {\\it``field-homomorphic''} if furthermore . Such relations would support oblivious processing of encrypted data. We propose a simple randomized encryption relation~  over the integers, called\\linebreak {\\it\\mbox {DoubleMod}}, which is``bounded ring-homomorphic''or what some call\" somewhat homomorphic.\" Here,``bounded''means that the number of additions and multiplications that can be performed, while not allowing the encrypted values to go out of range, is limited~(any pre-specified bound on the operation-count can be accommodated). Let  be any large integer. For any plaintext , DoubleMod encrypts  as , where  and  are randomly chosen integers in some appropriate interval, while  is the secret key. Here  is a large prime and the smallest prime factor of  exceeds . With knowledge of the key, but not of  and , the receiver decrypts the ciphertext by computing . DoubleMod generalizes an independent idea of van Dijk {\\it et al.} 2010. We present and refine a new CCA1 chosen-ciphertext attack that finds the secret key of both systems (ours and van Dijk {\\it et al.}'s) in linear time in the bit length of the security parameter. Under a known-plaintext attack, breaking DoubleMod is at most as hard as solving the {\\it Approximate GCD (AGCD)} problem. The complexity of AGCD is not known. We also introduce the\\mbox {{\\it SingleMod}}{field\u00a0\u2026",
        "Road traffic sensors provide us with rich multi-variable datastreams about the current traffic conditions. Occasionally, there are unusual traffic events (such as accidents, jams, severe weather, etc) that disrupt the expected road traffic conditions. Detecting the occurrence of such events in an online and real-time manner is useful to drivers in planning their routes and in the management of the transportation infrastructure. We propose a new method for detecting traffic events that impact road traffic conditions by extending the Bayesian Robust Principal Component Analysis (RPCA) approach. Our method couples multiple traffic datastreams so that they share a certain sparse structure. This sparse structure is used to localize traffic events in space and time. The traffic datastreams are measurements of different physical quantities (e.g. traffic flow, road occupancy) by different nearby sensors. Our proposed method process\u00a0\u2026",
        "With high spectral resolution hyperspectral imaging is capable of uncovering many subtle signal sources which cannot be known a priori or visually inspected. Such signal sources generally appear as anomalies in the data. Due to high correlation among spectral bands and sparsity of anomalies, a hyperspectral image can be e decomposed into two subspaces: a background subspace specified by a matrix with low rank dimensionality and an anomaly subspace specified by a sparse matrix with high rank dimensionality. This paper develops an approach to finding such low-high rank decomposition to identify anomaly subspace. Its idea is to formulate a convex constrained optimization problem that minimizes the nuclear norm of the background subspace and little \u03b91 norm of the anomaly subspace subject to a decomposition of data space into background and anomaly subspaces. By virtue of such a background\u00a0\u2026",
        "In a wireless sensor network, the sensors collect measurements from their local environments and build a model from those measurements in order to draw conclusions. Distributed model consensus allows sensors to make inferences about the global state of the deployment environment, by sharing models among the sensors, rather than raw data. In this paper, we analyze a regression model consensus framework based on graphical models. We compare its performance to a baseline alternative based on gossip averaging. Convergence and accuracy issues arise in the belief propagation used in the graphical model method, when the underlying communication topology contains cycles. Through simulation, we evaluate the performance on random geometric graph network topologies containing cycles."
    ],
    "title": [
        "\u202aUtilizing ultra-early continuous physiologic data to develop automated measures of clinical severity in a traumatic brain injury population\u202c",
        "\u202aConsensus\u2013relevance knn and covariate shift mitigation\u202c",
        "\u202aEvaluation of Tumor Development Using Hemoglobin Saturation Profile on Rodent Dorsal Window Chamber\u202c",
        "\u202aMethod and apparatus for predicting a use for a blood transfusion\u202c",
        "\u202aKnowledge graph inference using tensor embedding\u202c",
        "\u202aKnowledge graph fact prediction via knowledge-enriched tensor factorization\u202c",
        "\u202aEvaluation of a methodology for automated cell counting for streak mode imaging flow cytometry\u202c",
        "\u202aA computational streak mode cytometry biosensor for rare cell analysis\u202c",
        "\u202aInferring relations in knowledge graphs with tensor decompositions\u202c",
        "\u202aInferring Relations in Multirelational Knowledge Graphs with Tensor Decomposition\u202c",
        "\u202aIntelligent bus stop identification using smartphone sensors\u202c",
        "\u202aPredicting secondary insults after severe traumatic brain injury\u202c",
        "\u202aPermutation entropy analysis of vital signs data for outcome prediction of patients with severe traumatic brain injury\u202c",
        "\u202aAssessing surgical training: a utility analysis of the advanced surgical skills for exposure in trauma course\u202c",
        "\u202aForecasting new development of tumor areas using spatial and temporal distribution profiles of hemoglobin saturation in a mouse model\u202c",
        "\u202aDetecting road traffic events by coupling multiple timeseries with a nonparametric bayesian method\u202c",
        "\u202aDoubleMod and SingleMod: Simple randomized secret-key encryption with bounded homomorphicity\u202c",
        "\u202aSpatio-temporal coupled bayesian robust principal component analysis for road traffic event detection\u202c",
        "\u202aLow-rank decomposition-based anomaly detection\u202c",
        "\u202aDistributed model consensus for models of locally biased measurements in wireless sensor networks\u202c"
    ]
}