{
    "scholar_id": "9grfK9gAAAAJ",
    "name": "\u202aTinoosh Mohsenin\u202c - \u202aGoogle Scholar\u202c",
    "description": [
        " The increasing demand for efficient deep learning model deployment on Tiny Machine Learning (tinyML) and Edge platforms necessitates the development of methods that enable automated and effective network pruning, tailored to tinyML hardware constraints. In this paper, we present a novel differentiable pruning method that accepts total available memory on a tinyML hardware and employs saliency based measurements to identify and prune less significant connections within a deep neural network (DNN). Our approach integrates network compression within the training process, adapting resource utilization to the specific constraints of FPGAs, particularly focusing on on-chip memory. By leveraging a custom tinyML accelerator, we enable an efficient hardware-software co-design. Our framework further quantizes the model to int-8 to optimize the balance between model size and accuracy, crucial for tinyML\u00a0\u2026",
        "The advancement of sophisticated artificial intelligence (AI) algorithms has led to a notable increase in energy usage and carbon dioxide emissions, intensifying concerns about climate change. This growing problem has brought the environmental sustainability of AI technologies to the forefront, especially as they expand across various sectors. In response to these challenges, there is an urgent need for the development of sustainable AI solutions. These solutions must focus on energy-efficient embedded systems that are capable of handling diverse data types even in environments with limited resources, thereby ensuring both technological progress and environmental responsibility. Integrating complementary multimodal data into tiny machine learning models for edge devices is challenging due to increased complexity, latency, and power consumption. This work introduces TinyMNet-V3, a system that processes different modalities of complementary data, designs deep neural network (DNN) models, and employs model compression techniques including knowledge distillation and low bit-width quantization with memory-aware considerations to fit models within lower memory hierarchy levels, reducing latency and enhancing energy efficiency on resource-constrained devices. We evaluated TinyMNet-V3 in two multimodal case studies: COVID-19 detection using cough, speech, and breathing audios, and pose classification from depth and thermal images. With tiny inference models (6 KB and 58 KB), we achieved 92.95% and 90.7% accuracies, respectively. Our tiny machine learning models, deployed on resource limited hardware\u00a0\u2026",
        "Solving long-horizon, temporally-extended tasks using Reinforcement Learning (RL) is challenging, compounded by the common practice of learning without prior knowledge (or tabula rasa learning). Humans can generate and execute plans with temporally-extended actions and quickly learn to perform new tasks because we almost never solve problems from scratch. We want autonomous agents to have this same ability. Recently, LLMs have been shown to encode a tremendous amount of knowledge about the world and to perform impressive in-context learning and reasoning. However, using LLMs to solve real world problems is hard because they are not grounded in the current task. In this paper we exploit the planning capabilities of LLMs while using RL to provide learning from the environment, resulting in a hierarchical agent that uses LLMs to solve long-horizon tasks. Instead of completely relying on LLMs, they guide a high-level policy, making learning significantly more sample efficient. This approach is evaluated in simulation environments such as MiniGrid, SkillHack, and Crafter, and on a real robot arm in block manipulation tasks. We show that agents trained using our approach outperform other baselines methods and, once trained, don't need access to LLMs during deployment.",
        "Fine-tuning deep neural networks is pivotal for creating inference modules that can be suitably imported to edge or field-programmable gate array (FPGA) platforms. Traditionally, exploration of different parameters throughout the layers of deep neural networks has been done using grid search and other brute force techniques. Although these methods lead to the optimal choice of network parameters, the search process can be very time consuming and may not consider deployment constraints across different target platforms. This work addresses this problem by proposing Reg-Tune, a regression-based profiling approach to quickly determine the trend of different metrics in relation to hardware deployment of neural networks on tinyML platforms like FPGAs and edge devices. We start by training a handful of configurations belonging to different combinations of    or    workloads to\u00a0\u2026",
        "With the evaluation of Artificial Intelligence (AI), there has been a resurgence of interest in how to use AI algorithms on low-power embedded systems to broaden potential use cases of the Internet of Things (IoT). To mimic multimodal human perception, multimodal deep neural networks (M-DNN) have recently become very popular with the classification task due to their impressive performance for computer vision and audio processing tasks. This article presents TinyM2Net-V2\u2014a compact low-power software hardware architecture for multimodal deep neural networks for resource-constrained tiny devices. To compress the models to implement on tiny devices, cyclicly sparsification and hybrid quantization (4-bits weights and 8-bits activations) methods are used. Although model compression techniques are an active research area, we are the first to demonstrate their efficacy for multimodal deep neural networks\u00a0\u2026",
        "Traditional machine learning models often require powerful hardware, making them unsuitable for deployment on resource-limited devices. Tiny Machine Learning (tinyML) has emerged as a promising approach for running machine learning models on these devices, but integrating multiple data modalities into tinyML models still remains a challenge due to increased complexity, latency, and power consumption. This paper proposes TinyVQA, a novel multimodal deep neural network for visual question answering tasks that can be deployed on resource-constrained tinyML hardware. TinyVQA leverages a supervised attention-based model to learn how to answer questions about images using both vision and language modalities. Distilled knowledge from the supervised attention-based VQA model trains the memory aware compact TinyVQA model and low bit-width quantization technique is employed to further compress the model for deployment on tinyML devices. The TinyVQA model was evaluated on the FloodNet dataset, which is used for post-disaster damage assessment. The compact model achieved an accuracy of 79.5%, demonstrating the effectiveness of TinyVQA for real-world applications. Additionally, the model was deployed on a Crazyflie 2.0 drone, equipped with an AI deck and GAP8 microprocessor. The TinyVQA model achieved low latencies of 56 ms and consumes 693 mW power while deployed on the tiny drone, showcasing its suitability for resource-constrained embedded systems.",
        "Demand for efficient onboard object detection is increasing due to its key role in autonomous navigation. However, deploying object detection models such as YOLO on resource constrained edge devices is challenging due to the high computational requirements of such models. In this paper, an compressed object detection model named Squeezed Edge YOLO is examined. This model is compressed and optimized to kilobytes of parameters in order to fit onboard such edge devices. To evaluate Squeezed Edge YOLO, two use cases - human and shape detection - are used to show the model accuracy and performance. Moreover, the model is deployed onboard a GAP8 processor with 8 RISC-V cores and an NVIDIA Jetson Nano with 4GB of memory. Experimental results show Squeezed Edge YOLO model size is optimized by a factor of 8x which leads to 76% improvements in energy efficiency and 3.3x faster throughout.",
        "Solving long-horizon, temporally-extended tasks using Reinforcement Learning (RL) is challenging, compounded by the common practice of learning without prior knowledge (or tabula rasa learning). Humans can generate and execute plans with temporally-extended actions and quickly learn to perform new tasks because we almost never solve problems from scratch. We want autonomous agents to have this same ability. Recently, LLMs have been shown to encode a tremendous amount of knowledge about the world and to perform impressive in-context learning and reasoning. However, using LLMs to solve real world problems is hard because they are not grounded in the current task. In this paper we exploit the planning capabilities of LLMs while using RL to provide learning from the environment, resulting in a hierarchical agent that uses LLMs to solve long-horizon tasks. Instead of completely relying on LLMs, they guide a high-level policy, making learning significantly more sample efficient. This approach is evaluated in simulation environments such as MiniGrid, SkillHack, and Crafter, and on a real robot arm in block manipulation tasks. We show that agents trained using our approach outperform other baselines methods and, once trained, don't need access to LLMs during deployment.",
        "Edge Point of Care (POC) devices are crucial for human activity recognition (HAR) and fall detection because they enable real-time analysis and fast intervention, which can greatly improve outcomes in situations of patient and elderly monitoring. The emergence of Artificial Intelligence (AI) has sparked renewed enthusiasm for integrating AI algorithms into low-power embedded systems, broadening the potential applications of the POC devices. This paper introduces HAC-POCD, a system for multimodal human activity recognition and fall detection that processes different modalities of complementary images, designs deep neural network (DNN) models, and employs model compression techniques including knowledge distillation and low bit-width quantization with memory-aware considerations to fit models within lower memory hierarchy levels, reducing latency and enhancing energy efficiency on resource\u00a0\u2026",
        "Meta-reasoning shows promise in efficiently using the computational resources of tiny edge devices while performing highly computationally intensive reinforcement learning (RL) algorithms. We propose meta-reasoning for energy efficiency of multigoal RL, a hardware-aware framework that incorporates low-power preprocessing solutions and meta-reasoning to enable deployment of multigoal RL on tiny autonomous devices. For this aim, a meta-level is proposed to allocate resources efficiently in real time by switching between models with different complexities. Moreover, squeezed-edge you only look once (YOLO) is proposed for energy-efficient object detection in the preprocessing phase. For the experimental results, the proposed squeezed-edge YOLO was deployed on board a tiny drone named Crazyflie with a GAP8 processor that includes eight parallel RISC-V cluster cores. We compared latency and\u00a0\u2026",
        "Fine-tuning deep neural networks (DNNs) for deployment has traditionally relied on computationally intensive methods such as grid searches and neural architecture searches, which may not consider hardware-aware metrics. Moreover, it is essential to consider multiple objectives to develop a range of solutions for tiny machine learning hardware deployment with real-time latency and low power constraints. To address these problems, we propose Reg-TuneV2, a systematic approach to fine-tune DNNs for hardware deployment by considering multiple objectives, including accuracy, power, and latency contours. In addition, this approach uses metric learning to achieve smaller and better-suited configurations for deployment, achieving 90.5% accuracy with only 340 KB of memory for keyword spotting (KWS) on a field-programmable gate array. When compared to baselines for KWS and image classification on the Nvidia Jetson\u00a0\u2026",
        "Explainability of neural network prediction is essential to understand feature importance and gain interpretable insight into neural network performance. However, explanations of neural network outcomes are mostly limited to visualization, and there is scarce work that looks to use these explanations as feedback to improve model performance. In this work, model explanations are fed back to the feed-forward training to help the model generalize better. To this extent, a custom weighted loss where the weights are generated by considering the Euclidean distances between true LIME (Local Interpretable Model-Agnostic Explanations) explanations and model-predicted LIME explanations is proposed. Also, in practical training scenarios, developing a solution that can help the model learn sequentially without losing information on previous data distribution is imperative due to the unavailability of all the training data at\u00a0\u2026",
        "Robots have been successfully used to perform tasks with high precision. In real-world environments with sparse rewards and multiple goals, learning is still a major challenge and Reinforcement Learning (RL) algorithms fail to learn good policies. Training in simulation environments and then fine-tuning in the real world is a common approach. However, adapting to the real-world setting is a challenge. In this paper, we present a method named Ready for Production Hierarchical RL (ReProHRL) that divides tasks with hierarchical multi-goal navigation guided by reinforcement learning. We also use object detectors as a pre-processing step to learn multi-goal navigation and transfer it to the real world. Empirical results show that the proposed ReProHRL method outperforms the state-of-the-art baseline in simulation and real-world environments in terms of both training time and performance. Although both methods achieve a 100% success rate in a simple environment for single goal-based navigation, in a more complex environment and multi-goal setting, the proposed method outperforms the baseline by 18% and 5%, respectively. For the real-world implementation and proof of concept demonstration, we deploy the proposed method on a nano-drone named Crazyflie with a front camera to perform multi-goal navigation experiments.",
        "Safety, low-cost, small size, and Artificial Intelli-gence (AI) capabilities of drones have led to the proliferation of autonomous tiny Unmanned Aerial Vehicles (UAVs) in many applications which are dangerous, unknown, or time-consuming for humans. Deep Neural Networks (DNNs) have enabled au-tonomous navigation while using captured data by drone sensors as input to the model. Due to the extreme complexity of DNNs, cloud-based approaches have been highly addressed in which a drone is connected to the cloud and sends the data to the cloud, and takes the result. On the other hand, emerging tiny machine learning models and edge computing brings significant improvement in energy efficiency and latency with respect to cloud-based approaches. However, there is a trade-off in these two implementations for model accuracy, latency, and energy efficiency. For instance, applying tiny machine learning\u00a0\u2026",
        "Artificial Intelligence (AI) and Deep Neural Networks (DNNs) have attracted attention as a solution within autonomous systems fields as they enable applications such as visual perception and navigation. Although cloud-based approaches have already been highly addressed, there is a growing interest in using both AI and DNNs on the edge as this allows for lower latency and avoids the potential security concerns of transmitting data to a remote server. However, deploying DNNs on edge devices is challenging due to the limited computational power available, as well as energy efficiency being of the utmost importance. In this work, we introduce an approach named E2EdgeAI for Energy-Efficient Edge computing that takes advantage of AI for autonomous tiny drones. This approach optimizes the energy efficiency of DNNs by considering the effects of memory access and core utilization on the energy consumption\u00a0\u2026",
        "Compressive sensing is a simultaneous data acquisition and compression technique, which can significantly reduce data bandwidth, data storage volume, and power. We apply this technique for transient photometric events. In this work, we analyze the effect of noise on the detection of these events using compressive sensing (CS). We show numerical results on the impact of source and measurement noise on the reconstruction of transient photometric curves, generated due to gravitational microlensing events. In our work, we define source noise as background noise, or any inherent noise present in the sampling region of interest. For our models, measurement noise is defined as the noise present during data acquisition. These results can be generalized for any transient photometric CS measurements with source noise and CS data acquisition measurement noise. Our results show that the CS measurement matrix properties have an effect on CS reconstruction in the presence of source noise and measurement noise. We provide potential solutions for improving the performance by tuning some of the properties of the measurement matrices. For source noise applications, we show that choosing a measurement matrix with low mutual coherence can lower the amount of error caused due to CS reconstruction. Similarly, for measurement noise addition, we show that by choosing a lower expected value of the binomial measurement matrix, we can lower the amount of error due to CS reconstruction.",
        "Detection of respiratory symptoms has long been an area of extensive research to expedite the process of machine aided diagnosis for various respiratory conditions. This chapter attempts to address the early diagnosis of respiratory conditions using low power scalable software and hardware involving end-to-end convolutional neural networks (CNNs). We propose RespiratorNet, a scalable multimodal CNN software hardware architecture that can take audio recordings, speech information, and other sensor modalities belonging to patient demographic or symptom information as input to classify different respiratory symptoms. We analyze four different publicly available datasets and use them as case studies as part of our experiment to classify respiratory symptoms. With regards to fitting the network architecture to the hardware framework, we perform windowing, low bit-width quantization, and hyperparameter\u00a0\u2026",
        "Learning to solve long horizon temporally extended tasks with reinforcement learning has been a challenge for several years now. We believe that it is important to leverage both the hierarchical structure of complex tasks and to use expert supervision whenever possible to solve such tasks. This work introduces an interpretable hierarchical agent framework by combining planning and semantic goal directed reinforcement learning. We assume access to certain spatial and haptic predicates and construct a simple and powerful semantic goal space. These semantic goal representations are more interpretable, making expert supervision and intervention easier. They also eliminate the need to write complex, dense reward functions thereby reducing human engineering effort. We evaluate our framework on a robotic block manipulation task and show that it performs better than other methods, including both sparse and dense reward functions. We also suggest some next steps and discuss how this framework makes interaction and collaboration with humans easier.",
        "In this article, we propose an energy-efficient architecture, which is designed to receive both images and text inputs as a step toward designing reinforcement learning agents that can understand human language and act in real-world environments. We evaluate our proposed method on three different software environments and a low power drone named Crazyflie to navigate toward specified goals and avoid obstacles successfully. To find the most efficient language-guided reinforcement learning model, we implemented the model with various configurations of image input sizes and text instruction sizes on the Crazyflie drone GAP8, which consists of eight reduced instruction set computer-V cores. The task completion success rate and onboard power consumption, latency, and memory usage of GAP8 are measured and compared with Jetson TX2 ARM central processing unit and Raspberry Pi 4. The results show\u00a0\u2026",
        "Recently, Reinforcement Learning (RL) has shown great performance in solving sequential decision-making and control in dynamic environment problems. Despite its achievements, deploying Deep Neural Network (DNN)-based RL is expensive in terms of time and power due to the large number of episodes required to train agents with high dimensional image representations. Additionally, at the interference the large energy footprint of deep neural networks can be a major drawback. Embedded edge devices as the main platform for deploying RL applications are intrinsically resource-constrained and deploying deep neural network-based RL on them is a challenging task. As a result, reducing the number of actions taken by the RL agent to learn desired policy, along with the energy-efficient deployment of RL, is crucial. In this article, we propose Energy Efficient Hierarchical Reinforcement Learning (E2HRL\u00a0\u2026"
    ],
    "title": [
        "\u202aResource-Aware Saliency-Guided Differentiable Pruning for Deep Neural Networks\u202c",
        "\u202aTinyM $^ 2$ Net-V3: Memory-Aware Compressed Multimodal Deep Neural Networks for Sustainable Edge Deployment\u202c",
        "\u202aUsing LLMs for Augmenting Hierarchical Agents with Common Sense Priors\u202c",
        "\u202aReg-tune: A regression-focused fine-tuning approach for profiling low energy consumption and latency\u202c",
        "\u202aTinyM2Net-V2: A Compact Low-power Software Hardware Architecture for M ulti m odal Deep Neural Networks\u202c",
        "\u202aTinyVQA: Compact Multimodal Deep Neural Network for Visual Question Answering on Resource-Constrained Devices\u202c",
        "\u202aSqueezed Edge YOLO: Onboard Object Detection on Edge Devices\u202c",
        "\u202aLLM Augmented Hierarchical Agents\u202c",
        "\u202aHAC-POCD: Hardware-Aware Compressed Activity Monitoring and Fall Detector Edge POC Devices\u202c",
        "\u202aMetae2rl: Toward metareasoning for energy-efficient multi-goal reinforcement learning with squeezed edge yolo\u202c",
        "\u202aReg-TuneV2: Hardware-Aware and Multi-Objective Regression-Based Fine-Tuning Approach for DNNs on Embedded Platforms\u202c",
        "\u202aHarnessing the Power of Explanations for Incremental Training: A LIME-Based Approach\u202c",
        "\u202aReProHRL: Towards multi-goal navigation in the real world using hierarchical agents\u202c",
        "\u202aMlae2: Metareasoning for latency-aware energy-efficient autonomous nano-drones\u202c",
        "\u202aE2edgeai: Energy-efficient edge computing for deployment of vision-based dnns on autonomous tiny drones\u202c",
        "\u202aApplication of Compressive Sensing in the Presence of Noise for Transient Photometric Events\u202c",
        "\u202aA Re-configurable Software-Hardware CNN Framework for Automatic Detection of Respiratory Symptoms\u202c",
        "\u202aTowards an interpretable hierarchical agent framework using semantic goals\u202c",
        "\u202aEfficient language-guided reinforcement learning for resource-constrained autonomous systems\u202c",
        "\u202aE2hrl: An energy-efficient hardware accelerator for hierarchical deep reinforcement learning\u202c"
    ]
}