{
    "scholar_id": "03Bww5gAAAAJ",
    "name": "\u202aChein-I Chang\u202c - \u202aGoogle Scholar\u202c",
    "description": [
        "Target detection is a fundamental task of hyperspectral imaging where constrained energy minimization (CEM) has been widely used for subpixel target detection techniques. Due to its effectiveness, CEM has been generalized to various versions, such as kernel CEM (KCEM), kernel target-constrained interference-minimized filter (KTCIMF), ensemble cascaded CEM (ECEM), and hierarchical CEM (HCEM). Unfortunately, these generalizations overlooked the key design rationale behind CEM. This article revisits CEM for hyperspectral target detection (HTD) and proves how and why it works mathematically. Specifically, several new CEM generalizations are derived and particularly noteworthy. By including spatial information in an iterative process, KCEM, ECEM, and HCEM can be generalized to iterative KCEM (IKCEM), iterative KTCIMF (IKTCIMF), iterative ECEM (IECEM), and iterative HCEM (IHCEM). Also, by\u00a0\u2026",
        "Hepatocyte nucleus segmentation in histopathology images is vital for diagnostics. However, varying slide background due to cutting and staining poses a great challenge for domain-agnostic segmentation, which limits model generalization. This paper first proposes an anti-background perturbation consistency (APC) loss to mitigate the influence of image background on model decisions and controlled background perturbations to enhance generalizability, while still maintaining feature consistency. Since convolutional neural networks (CNNs) often prioritize local texture over global shape which also limits generalization, we then introduce the concept of local self-information into the texture probability (TP) loss to reduce over-focus of CNN on local textures. To avoid model convergence to saddle points during training which yields varying outcomes and unstable performance, we finally conclude with a meta-learner\u00a0\u2026",
        "Band clustering has been widely used for hyperspectral band selection (BS). However, selecting an appropriate band to represent a band cluster is a key issue. Density peak clustering (DPC) provides an effective means for this purpose, referred to as DPC-based BS (DPC-BS). It uses two indicators, cluster density and cluster distance, to rank all bands for BS. This paper reinterprets cluster density and cluster distance as band local density (BLD) and band distance (BD) and also introduces a new concept called band prominence value (BPV) as a third indicator. Combining BLD and BD with BPV derives new band prioritization criteria for BS, which can extend the currently used DPC-BS to a new DPC-BS method referred to as band density prominence clustering (BDPC). By taking advantage of the three key indicators of BDPC, i.e., cut-off band distance bc, k nearest neighboring-band local density, and BPV, two versions of BDPC can be derived called bc-BDPC and k-BDPC, both of which are quite different from existing DPC-based BS methods in three aspects. One is that the parameter bc of bc-BDPC and the parameter k of k-BDPC can be automatically determined by the number of clusters and virtual dimensionality (VD), respectively. Another is that instead of using Euclidean distance, a spectral discrimination measure is used to calculate BD as well as inter-band correlation. The most important and significant aspect is a novel idea that combines BPV with BLD and BD to derive new band prioritization criteria for BS. Extensive experiments demonstrate that BDPC generally performs better than DPC-BS as well as many current state-of-the art BS\u00a0\u2026",
        "Gaussian pyramid (GP) is a commonly used image coding technique that encodes an image as a pyramid that is stacked by a set of images with Gaussian window-reduced sizes and multiple spatial resolutions. Associated with GP, a Laplacian pyramid (LP) can be also constructed to represent differential images between images in two consecutive layers of GP. Such resulting Gaussian\u2013Laplacian pyramid (GLP) performs data compression in a lossless and lossy manner. A convolutional neural network (CNN) consists of a series of layers concatenated in a feedforward manner where each layer has a convolutional sublayer (CL) and a pooling sublayer (PL). Interestingly, each layer implemented by CL and PL in a CNN can be realized by a single layer in GP in the sense that CL and PL can be carried out by a low-pass Gaussian filter operated as a Gaussian kernel in a single layer of GP. This article develops a new\u00a0\u2026",
        "For scenes with complex backgrounds and weak anomalies, how to effectively distinguish anomaly targets from the background is the key to perform hyperspectral image (HSI) anomaly detection (AD). Data decomposition-based methods have been widely studied due to their potential in separating background and anomaly components. However, due to its unclean background extraction and sensitivity to noise, it has an adverse effect on the detection of anomaly targets. In addition, a large amount of spectral data can lead to an increase in computation during data decomposition. To address this issue, we propose an AD method based on a feedback band group and variation low-rank (LR) sparse model (FBGVLRS-AD). First, we employ a uniform band selection (BS) strategy to partition spectral bands and perform data decomposition on the selected band group, to separate LR and sparse components. This\u00a0\u2026",
        "Oriented to adaptive recognition of the new land-cover categories, incremental classification (IC) that aims to complete adaptive classification with continuous learning is urgent and crucial for hyperspectral image classification (HSIC). Nevertheless, deep-learning-based HSIC models adopted the learning paradigm with fixed classes yield unsatisfactory inference in the situation of IC due to the catastrophic forgetting problem. To eliminate the recognition gap and maintain the old knowledge during IC, in this article, we propose a novel approach called the distillation-constrained prototype representation network (DCPRN) for hyperspectral image IC (HSIIC). The primary goal of DCPRN is to enhance the discriminative capability for recognizing the original classes in HSIIC while effectively integrating both the original and the incremental knowledge to facilitate adaptive learning. Specifically, the proposed framework\u00a0\u2026",
        "Whether or not a hyperspectral anomaly detector is effective is determined by two crucial issues, anomaly detectability and background suppressibility (BS), both of which are very closely related to two factors, the datasets used for a selected hyperspectral anomaly detector and detection measures used for its performance evaluation. This paper explores how anomaly detectability and BS play key roles in hyperspectral anomaly detection (HAD). To address these two issues, we investigate three key elements attributed to HAD. One is a selected hyperspectral anomaly detector, and another is the datasets used for experiments. The third one is the detection measures used to evaluate the effectiveness of a hyperspectral anomaly detector. As for hyperspectral anomaly detectors, twelve commonly used anomaly detectors were evaluated and compared. To address the appropriate use of datasets for HAD, seven popular and widely used datasets were studied for HAD. As for the third issue, the traditional area under a receiver operating characteristic (ROC) curve of detection probability\u2014PD versus false alarm probability, PF, (AUC(D,F))\u2014was extended to 3D ROC analysis where a 3D ROC curve was developed to generate three 2D ROC curves from which eight detection measures could be derived to evaluate HAD in all round aspects, including anomaly detectability, BS and joint anomaly detectability and BS. Qualitative analysis showed that many works reported in the literature which claimed that their developed hyperspectral anomaly detectors performed better than other anomaly detectors are actually not true because they overlooked these two\u00a0\u2026",
        "This article investigates four issues, background (BKG) suppression (BS), anomaly detectability, noise effect, and interband correlation reduction (IBCR), which have significant impacts on its performance. Despite that a recently developed effective anomaly space (EAS) was designed to use data sphering (DS) to remove the second-order data statistics characterized by BKG, enhance anomaly detectability, and reduce noise effect, it does not address the IBCR issue. To cope with this issue, this article introduces band sampling (BSam) into EAS to reduce IBCR and further suppress BKG more effectively. By implementing EAS in conjunction with BSam (EAS-BSam), these four issues can be resolved altogether for any arbitrary anomaly detector. It first modifies iterative spectral\u2013spatial hyperspectral anomaly detection (ISSHAD) to develop a new variant of ISSHAD, called iterative spectral\u2013spatial maximal map (ISSMax\u00a0\u2026",
        "Real-time anomaly detection technique can efficiently and effectively leverage available data and operates in tandem with data collection, avoiding dependence on unacquired spectral data. Nonetheless, there are no restrictions or discussions regarding the scope of utilization for existing data. Overloading the analysis with excessive information, particularly encompassing dynamically changing background scenes, can introduce interference, undermining the statistical characteristics of the data and hampering anomaly detection. Studies indicate that local anomaly detection can enhance detection performance. Consequently, determining the optimal scope of the row space within the context of real-time line-by-line processing by integrating local processing and real-time technology stands pivotal in enhancing efficacy. In order to realize real-time hyperspectral local anomaly detection, based on the most widely used push\u00a0\u2026",
        "Due to significant interband correlation resulting from the use of hundreds of contiguous spectral bands, band selection (BS) is one of the most widely used methods to reduce data dimensionality for band redundancy removal. A challenge for BS is how to design an effective criterion that can select bands with preserving crucial spectral information, while also avoiding selecting highly correlated bands. Information theory turns out to be one of the best means to address such issues in terms of information redundancy, specifically, the rate distortion function (RDF) of Shannon\u2019s third noisy source coding (or joint source and channel coding) theorem, which has been widely used in image compression/coding. This article presents a novel unsupervised RDF-based band subset selection (RDFBSS) for hyperspectral image classification (HSIC). To accomplish this goal, a new concept of the area under an RDF curve,  \u00a0\u2026",
        "In this paper, we build a platform that can automatically and rapidly detect Fusarium wilt on Phalaenopsis. We have also developed a portable handheld multispectral imaging device (PHMID) that contains six LEDs representing six spectral bands, making it easier to use in the field. The Automatic Target Generation Process (ATGP) and the Spectral Angle Mapper (SAM) are used to obtain the desired signal on a high-spectral image. The Harsany-Farrand-Chang (HFC) method is used for band selection to estimate the number of different spectral bands. We use deep neural networks (DNNs), support vector machines (SVMs), and random forest classifiers (RFCs) for classification. The best detection accuracy of VNIR, SWIR and PHMID was 95.77%, 91.72% and 90.84%, respectively.",
        "Convolutional neural network (CNN) has received considerable interest in hyperspectral image classification (HSIC) lately due to its excellent spectral\u2013spatial feature extraction capability. To improve CNN, many approaches have been directed at exploring the infrastructure of its network by introducing different paradigms. This article takes a rather different approach by developing an iterative CNN that extends a CNN by including a feedback system to repeatedly process the same CNN in an iterative manner. Its idea is to take advantage of a recently developed iterative training sampling spectral\u2013spatial classification (IRTS-SSC) that allows CNN to update its spatial information of classification maps through a feedback spatial fil- tering system via IRTS. The resulting CNN is called iterative random training sampling CNN (IRTS-CNN) with several unique features. First, IRTS-CNN combines CNN and IRTS-SSC into\u00a0\u2026",
        "A novel method for near-infrared (NIR) spectroscopy spectra standardization is presented. NIR spectroscopies have been widely used in analytical chemistry, and many methods have been developed for NIR spectra standardization. To establish a robust standardization transformation, most existing methods require spectral data sets from both primal and secondary instruments for 1-1 correspondence validation. However, this limits the usage of standardization methods. This paper investigates an interesting issue, \u201cCan spectra data in sets be arbitrarily order?\u201d and further develops a completely different approach from existing methods in view of statistical signal processing. The key idea is to first compensate for the distortion along the wavelength and intensity of the spectra, and then transfer the second order statistic (2OS) from the primal spectra to the secondary spectra via data sphering and an inverse sphering\u00a0\u2026",
        "Anomaly detection (AD) requires spectral and spatial information to differentiate anomalies from their surrounding data samples. To capture spatial information, a general approach is to utilize local windows in various forms to adapt local characteristics of the background (BKG) from which unknown anomalies can be detected. This article develops a new approach, called iterative spectral\u2013spatial hyperspectral AD (ISSHAD), which can improve an anomaly detector in its performance via an iterative process. Its key idea is to include an iterative process that captures spectral and spatial information from AD maps (ADMaps) obtained in previous iterations and feeds these anomaly maps back to the current data cube to create a new data cube for the next iteration. To terminate the iterative process, a Tanimoto index (TI)-based automatic stopping rule is particularly designed. Three types of spectral and spatial information\u00a0\u2026",
        "Despite continuing to progress in hyperspectral image classification (HSIC) based on deep learning, the classification accuracy is limited to further improve in the absence of labeled samples. To address this issue, the metric-based prototypical networks for few-shot learning have enjoyed widespread popularity. However, the conventional prototypical networks are vulnerable to the selected examples and fail to accomplish representative predictions for the prototypes in complicated situations. In this article, we propose a multiview calibrated prototype-learning framework for few-shot HSIC, which consists of three rectified strategies from different views to improve the robustness of prototypes in the embedding space. Specifically, the calibrated aggregation network is the first presented to calibrate the representations with local patches\u2019 aggregation for the enhancement of the prototypes. Moreover, to improve the\u00a0\u2026",
        "Advances in Hyperspectral Image Processing Techniques Authoritative and comprehensive resource covering recent hyperspectral imaging techniques from theory to applications Advances in Hyperspectral Image Processing Techniques is derived from recent developments of hyperspectral imaging (HSI) techniques along with new applications in the field, covering many new ideas that have been explored and have led to various new directions in the past few years. The work gathers an array of disparate research into one resource and explores its numerous applications across a wide variety of disciplinary areas. In particular, it includes an introductory chapter on fundamentals of HSI and a chapter on extensive use of HSI techniques in satellite on-orbit and on-board processing to aid readers involved in these specific fields. The book\u2019s content is based on the expertise of invited scholars and is categorized into six parts. Part I provides general theory. Part II presents various Band Selection techniques for Hyperspectral Images. Part III reviews recent developments on Compressive Sensing for Hyperspectral Imaging. Part IV includes Fusion of Hyperspectral Images. Part V covers Hyperspectral Data Unmixing. Part VI offers different views on Hyperspectral Image Classification. Specific sample topics covered in Advances in Hyperspectral Image Processing Techniques include: Two fundamental principles of hyperspectral imaging Constrained band selection for hyperspectral imaging and class information-based band selection for hyperspectral image classification Restricted entropy and spectrum properties for hyperspectral imaging and\u00a0\u2026",
        "                          This chapter introduces a new band selection (BS) approach to hyperspectral image classification, called progressive band selection processing of hyperspectral image classification (PBSP\u2010HSIC), which performs image classification stage\u2010by\u2010stage progressively in the sense that each stage performs HSIC according to a specifically selected band subset. Its idea is first to introduce a criterion, referred to as class classification priority (CCP), to measure the priority of each class to be classified. These calculated CCP probabilities are then used to construct a                          p                         \u2010ary Huffman coding tree (HCT) to navigate classification to be performed layer\u2010by\u2010layer where each layer is specified by a classification stage that selects a particular band subset to perform classification. Finally, classification is performed layer\u2010by\u2010layer along the HCT from top to down\u00a0\u2026",
        "                          This chapter extends band selection (BS) in Chapter 4, which selects bands one at a time to band subset selection (BSS), which selects multiple bands simultaneously as a band subset. The key issue arising in BSS but not in BS is that BSS requires exhausting all possible band subsets to find an optimal band subset, which is practically infeasible. The BSS to be presented in this chapter reinvents a wheel by interpreting each selected band as a desirable endmember from an endmember\u2010finding viewpoint so that finding an optimal band subset is equivalent to finding an optimal set of endmembers. Its idea is to first use virtual dimensionality (VD) to determine the number of multiple bands to be selected as a band subset,                          n BS                         . Then, BSS is performed by two iterative processes, sequential band subset\u00a0\u2026",
        " Despite that hyperspectral technology has continued to improve over the years, it still has practical constraints on size, weight, and power (SWaP). One major issue is its use of a large number of very fine spectral bands which creates challenges in both data archival and processing. Compressive sensing (CS) becomes an enabling technology that can be used to reduce the overall data processing and SWaP requirements. This chapter explores the viability of performing classification for hyperspectral data on a compressively sensed band domain (CSBD) via CS instead of operating the original data space (ODS). In particular, the well\u2010known restricted isometry property (RIP) and a random spectral sampling strategy are investigated for hyperspectral image classification (HSIC) in CSBD. A mathematical analysis is also presented to show that the classification error can be expressed in\u00a0\u2026",
        " This chapter explores two fundamental principles, pigeon\u2010hole principle and orthogonality principle, behind design and development of hyperspectral image processing algorithms in various applications. The pigeon\u2010hole principle has found its applications in estimating the number of endmembers required by spectral unmixing, the number of spectrally distinct signatures by virtual dimensionality (VD), orders of low rank and sparse representation (LRaSR)/low rank and sparse matrix decomposition (LRaSMD), the number of bands to be selected for band selection (BS) and number of bands to be sampled for band sampling (BSam). The orthogonality principle can be used as a criterion to derive the orthogonal subspace projection (OSP) technique in developing algorithms for finding endmembers, detecting subpixel targets, anomalies as well as OSP\u2010based LRaSMD in target\u00a0\u2026"
    ],
    "title": [
        "\u202aConstrained Energy Minimization (CEM) for Hyperspectral Target Detection: Theory and Generalizations\u202c",
        "\u202aDomain Generalization with Anti-background Perturbation Consistency and Texture Reduction Ensemble Models for Hepatocyte Nucleus Segmentation\u202c",
        "\u202aBand Selection via Band Density Prominence Clustering for Hyperspectral Image Classification\u202c",
        "\u202aIterative Gaussian\u2013Laplacian Pyramid Network for Hyperspectral Image Classification\u202c",
        "\u202aFeedback Band Group and Variation Low Rank Sparse Model for Hyperspectral Image Anomaly Detection\u202c",
        "\u202aDistillation-constrained prototype representation network for hyperspectral image incremental classification\u202c",
        "\u202aExploration of data scene characterization and 3D ROC evaluation for hyperspectral anomaly detection\u202c",
        "\u202aBand sampling of hyperspectral anomaly detection in effective anomaly space\u202c",
        "\u202aHyperspectral Real-Time Local Anomaly Detection Based on Finite Markov via Line-by-Line Processing\u202c",
        "\u202aUnsupervised rate distortion function-based band subset selection for hyperspectral image classification\u202c",
        "\u202aDetection and Analysis of Phalaenopsis Fusarium Wilt Using Machine Learning\u202c",
        "\u202aIterative random training sampling convolutional neural network for hyperspectral image classification\u202c",
        "\u202aStandardization of near infrared spectroscopies via sample spectral correlation equalization\u202c",
        "\u202aIterative spectral\u2013spatial hyperspectral anomaly detection\u202c",
        "\u202aMultiview calibrated prototype learning for few-shot hyperspectral image classification\u202c",
        "\u202aAdvances in Hyperspectral Image Processing Techniques\u202c",
        "\u202aProgressive Band Selection Processing for Hyperspectral Image Classification\u202c",
        "\u202aBand Subset Selection for Hyperspectral Imaging\u202c",
        "\u202aHyperspectral Image Classification in Compressively Sensed Band Domain\u202c",
        "\u202aIntroduction: Two fundamental principles behind hyperspectral imaging\u202c"
    ]
}