{
    "scholar_id": "G5dmv5oAAAAJ",
    "description": [
        "This position paper explores the potential of WebXR compatibility for increased impact from large-scale visualization environments housed in immersive visualization laboratories. In a rapidly evolving landscape of highly performant extended reality (XR) head-mounted displays (HMDs), the ability to develop software which can meaningfully utilize relative strengths of different visualization tools is paramount. We explore how use of standards such as WebXR for broadly platform-agnostic immersive visualization compares to traditional methods of more tailored development, noting costs and benefits of each approach.",
        "Virtual reality is progressively more widely used to support embodied AI agents, such as robots, which frequently engage in \u2018sim-to-real\u2019 based learning approaches. At the same time, tools such as large vision-and-language models offer new capabilities that tie into a wide variety of tasks and capabilities. In order to understand how such agents can learn from simulated environments, we explore a language model\u2019s ability to recover the type of object represented by a photorealistic 3D model as a function of the 3D perspective from which the model is viewed. We used photogrammetry to create 3D models of commonplace objects and rendered 2D images of these models from an fixed set of 420 virtual camera perspectives. A well-studied image and language model (CLIP) was used to generate text (i.e., prompts) corresponding to these images. Using multiple instances of various object classes, we studied which\u00a0\u2026",
        "The melting of the ice sheets covering Greenland and Antarctica is one of the largest contributors to sea level rise. A better understanding of the internal structure and dynamics of Earth's ice sheets is necessary for glaciologists to accurately make projections of future glacier change. But ice sheets are complex, multi-dimensional systems, studied using imagery from space, geophysical observations collected from the air, and 3D models of their flow history and modern change. Data visualization techniques currently limit our ability to cross-validate datasets and models, with particular need for better visualization of ice penetrating radar, used to capture the internal structure and layers of glaciers. Current data visualization strategies center around fence diagrams, which provide a visual, 3D context for these 2D radar images, typically rendered on 2D displays. Our development of a WebXR system for viewing fence\u00a0\u2026",
        "We are developing an extended reality (XR) tool for immersive visualization of climate and weather simulations, to provide climate scientists with better and faster insights into climate model data. The Visualization And Lagrangian dynamics Immersive eXtended Reality (VALIXR) toolkit is being initially designed to work with the NASA Goddard Earth Observing System (GEOS), a high resolution, mature, Earth system model. While other visualizations are based on an Eulerian perspective, with the earth divided into a grid where each square shows different physical attributes over time, we are instead building our visualization around a Lagrangian approach. We have added a trajectory model to GEOS, which can track and output budget terms (eg, momentum) and parcel attributes that describe their dynamics (eg, temperature) as moving particles of data to then be visualized in our XR tool.",
        "Human-robot interaction is a critical area of research, providing support for collaborative tasks where a human instructs a robot to interact with and manipulate objects in an environment.",
        " Historic cemeteries face ravages of time, weather, and vandalism. We first captured hundreds of images for each of several unindexed historic cemeteries. We then used a high performance computing system to orthorectify these images into ultraresolution (billions of pixels), georeferenced, tiled images. Here, we describe the interactive visualization we developed using these tiled images to enable volunteers to collaboratively map graves and identify burials. Our ongoing work tests the capacity of this visualization to enable coordination between volunteers with distinct and often asynchronous assignments, including photography, mapping, research, and restoration.",
        " The melting of the ice sheets covering Greenland and Antarctica are primary drivers of sea level rise. Predicting the rate of ice loss depends on modeling the ice dynamics. Ice penetrating radar provides the ability to capture images through the ice sheet, down to the bedrock. Historical environmental and climate perturbations cause small changes to the dielectric constant of ice, which are visually manifested as layers of varying brightness in the radar imagery. To understand how the flow of ice has progressed between neighboring image slices, glaciologists use Fence Diagrams to visualize several cross-sections at once. Here, we describe the immersive virtual reality (VR) fence diagrams we have developed. The goal of our system is to enable glaciologists to make sense of these data and thereby predict future ice loss. ",
        "Our work explores the use of extended reality (XR) to improve scientific discovery with numerical weather/climate models that inform Earth science digital twins, specifically the NASA Goddard Earth Observing System (GEOS) global atmospheric model. The overall project is named the Visualization And Lagrangian dynamics Immersive eXtended Reality Toolkit (VALIXR), which has two main areas of focus: (1) enhancing the understanding of and interaction with model output data through advanced visualizations in the XR environment, and (2) the integration of Lagrangian dynamics into the GEOS model, which allows a natural, feature-specific analysis of Earth science phenomena as opposed to traditional, fixed-point Eulerian dynamics. Here, we report initial work on these focus areas.",
        "Ice layers in glaciers, such as those covering Greenland and Antarctica, are deformed over time. The deformations of these layers provide a record of climate history and are useful in predicting future ice flow and ice loss. Cross sectional images of the ice can be captured by airborne radar and layers in the images then annotated by glaciologists. Recent advances in semi-automated and automated annotation allow for significantly more annotations, but the validity of these annotations is difficult to determine because ground-truth (GT) data is scarce. In this paper, we (1) propose GT-dependent and GT-independent metrics for layer annotations and (2) present results from our implementation and initial testing of GT-independent metrics, such as layer breakpoints, local layer density, spatial frequency, and layer orientation agreement.",
        "Earth\u2019s ice sheets are the largest contributor to sea level rise. For this reason, understanding the flow and topology of ice sheets is crucial for the development of accurate models and predictions. In order to aid in the generation of such models, ice penetrating radar is used to collect images of the ice sheet through both airborne and ground-based platforms. Glaciologists then take these images and visualize them in 3D fence diagrams on a flat 2D screen. We aim to consider the benefits that an XR visualization of these diagrams may provide to enable better data comprehension, annotation, and collaborative work. In this paper, we discuss our initial development and evaluation of such an XR system.",
        "The overarching goal of this work is to enable the collection of language describing a wide variety of objects viewed in virtual reality. We aim to create full 3D models from a small number of \u2018keyframe\u2019images of objects found in the publicly available Grounded Language Dataset (GoLD) using photogrammetry. We will then collect linguistic descriptions by placing our models in virtual reality and having volunteers describe them. To evaluate the impact of virtual reality immersion on linguistic descriptions of the objects, we intend to apply contrastive learning to perform grounded language learning, then compare the descriptions collected from images (in GoLD) versus our models.",
        "While VR as an interface for the teleoperation of robots has been well-studied in recent years, VR can also be used to advance our understanding of in-person human-robot interaction (HRI) by sim-ulating such interactions more repeatably and affordably than real-world studies. A few platforms now exist for studying human-robot interaction in VR, but little of this work has involved the study of the realism of specific, typical in-person HRI tasks. To evaluate this realism, we conduct a user study consisting of a collaborative assembly task where a robot and human work together to build a simple electrical circuit. We present a comparison of the task performed in the real world versus with virtual robot in VR. We discuss difficulties encountered and draw conclusions about what characteristics a virtual environment should have in order to support physical human-robot interactions.",
        "In this paper, we present a shared manipulation task performed both in virtual reality with a simulated robot and in the real world with a physical robot. A collaborative assembly task where the human and robot work together to construct as simple electrical circuit was chosen. While there are platforms available for conducting human robot interactions using virtual reality, there has not been significant work investigating how it can influence human perception of tasks that are typically done in person. We present an overview of the simulation environment used, describe the paired experiment being performed, and finally enumerate a set of design desiderata to be considered when conducting sim2real experiment involving humans in a virtual setting.",
        " Background Cyber defense decision-making during cyber threat situations is based on human-to-human communication aiming to establish a shared cyber situational awareness. Previous studies suggested that communication inefficiencies were among the biggest problems facing security operation center teams. There is a need for tools that allow for more efficient communication of cyber threat information between individuals both in education and during cyber threat situations. Methods In the present study, we compared how the visual representation of network topology and traffic in 3D mixed reality vs. 2D affected team performance in a sample of cyber cadets (N = 22) cooperating in dyads. Performance outcomes included network topology recognition, cyber situational awareness, confidence in judgements, experienced communication demands, observed verbal communication, and forced choice decision-making. The study utilized network data from the NATO CCDCOE 2022 Locked Shields cyber defense exercise. Results We found that participants using the 3D mixed reality visualization had better cyber situational awareness than participants in the 2D group. The 3D mixed reality group was generally more confident in their judgments except when performing worse than the 2D group on the topology recognition task (which favored the 2D condition). Participants in the 3D mixed reality group experienced less communication demands, and performed more verbal communication aimed at establishing a shared mental model and less communications discussing task resolution. Better communication was associated with better cyber\u00a0\u2026",
        " After project organizers used a drone to create a high-resolution aerial map of a historic cemetery, sets of volunteers served in four distinct, interdependent roles to photograph, research, restore, and geospatially index the cemetery\u2019s many unrecorded interments. Here, we share observations from our initial tests of this approach, which included a visit of volunteers for synchronous on-site work. We explore the differences in volunteer behavior and performance relative to organizer expectations and how the interdependence of the four roles is impacted by these differences.",
        "The versatility and performance of mobile devices has increased greatly in recent years, allowing users to perform more tasks in daily life. While mobile devices and applications provide many benefits for users, some of the most significant are locationbased, including point-of-use tools, navigation, and alert systems. This paper presents a prototype of a cross-platform mobile augmented reality (AR) application with the core purpose of finding a better means to keep a campus community secure and connected. This mobile AR application consists of four core functionalities\u2013an events system, a policing system, a directory system, and a notification system. The events system keeps the community up to date on events that are happening or will soon be happening on campus. The policing system allows the community to stay in arms reach of campus resources that help them to stay secure. The directory system serves as a one-stop shop for campus resources, ensuring that staff, faculty, and students will have a convenient and efficient means of accessing pertinent information on the campus departments. This paper demonstrates how augmented reality (AR) visualizations could be used to supplement existing emergency communications for alert and safety in built spaces. This work highlights the ability to provide evacuation information in a multileveled space in 3D form using AR technology. Specifically, the paper describes the design and implementation of the proposed mobile AR application and reports the results of the pilot study conducted to evaluate perceived ease-of-use and usability. results from this pilot study show that the mobile AR\u00a0\u2026",
        "View Video Presentation: https://doi.org/10.2514/6.2023-2674.vidMaritime remote sensing (MRS) is a multi-disciplinary and multi-physics field at the intersection of naval hydrodynamics, physical oceanography, overhead platforms, and electro-optical sensors. One proposed improvement to MRS information gathering and operations is the use of swarms of autonomous surface, aerial, and/or undersea vehicles as a multi-agent system (MAS) to automate data collection, data processing, and situational awareness.  Here, we explore the design of an autonomous multi-agent system with the objective of containing a target object, i.e., surrounding the object in a loosely defined shape. The agents make decisions using reinforcement learning by way of a Markov decision process. Our current proof-of-concepts are modeled using Python-based 2D simulation environments which contain our agents and target used for\u00a0\u2026",
        "The accurate registration of astronomical images without a world coordinate system or authoritative catalog is useful for visually enhancing the spatial resolution of multiple images containing the same target. Increasing the resolution of images through super-resolution (SR) techniques can improve the performance of commodity optical hardware, allowing more science to be done with cheaper equipment. Many SR techniques rely on the accurate registration of input images, which is why this work is focused on accurate star finding and registration. In this work, synthetic star field frames are used to explore techniques involving star detection, matching, and transform-fitting. Using Moffat stellar profiles for stars, non-maximal suppression for control-point finding, and gradient descent for point finding optimization, we are able to obtain more accurate transformation parameters than that provided other modern\u00a0\u2026",
        "Cybersecurity practitioners face the challenge of monitoring complex and large datasets. These could be visualized as time-varying node-link graphs, but would still have complex topologies and very high rates of change in the attributes of their links (representing network activity). It is natural, then, that the needs of the cybersecurity domain have driven many innovations in 2D visualization and related computer-assisted decision making. Here, we discuss the lessons learned while implementing user interactions for Virtual Data Explorer (VDE), a novel system for immersive visualization (both in Mixed and Virtual Reality) of complex time-varying graphs. VDE can be used with any dataset to render its topological layout and overlay that with time-varying graph; VDE was inspired by the needs of cybersecurity professionals engaged in computer network defense (CND).Immersive data visualization using VDE enables\u00a0\u2026",
        "Interactive Data Visualizations (IDV) can be useful for cybersecurity subject matter experts (CSMEs) while they are exploring new data or investigating familiar datasets for anomalies, correlating events, etc. For an IDV to be useful to a CSME, interaction with that visualization should be simple and intuitive (free of additional mental tasks) and the visualization\u2019s layout must map to a CSME\u2019s understanding. While CSMEs may learn to interpret visualizations created by others, they should be encouraged to visualize their datasets in ways that best reflect their own ways of thinking. Developing their own visual schemes makes optimal use of both the data analysis tools and human visual cognition. In this article, we focus on a currently available interactive stereoscopically perceivable multidimensional data visualization solution, as such tools could provide CSMEs with better perception of their data compared to interpreting IDV on flat media (whether visualized as 2D or 3D structures)."
    ],
    "title": [
        "\u202aWebXR, CAVEs, and the Balance of XR Platform Agnosticity Versus Performance in Immersive Scientific Visualization\u202c",
        "\u202aA Large Model\u2019s Ability to Identify 3D Objects as a Function of Viewing Angle\u202c",
        "\u202aInitial Development of a WebXR Platform for Ice Penetrating Radar Data, to Improve our Understanding of Polar Ice Sheets\u202c",
        "\u202aLagrangian Visualization using Immersive Extended Reality for Earth System Models\u202c",
        "\u202aA Collaborative Building Task in VR Vs. Reality\u202c",
        "\u202aDrones, Phones, and Stones: Visualization for Collaborative Digitization of Historic Cemeteries\u202c",
        "\u202aVisualizing the greenland ice sheet in VR using immersive fence diagrams\u202c",
        "\u202aUsing xr for improving scientific discovery with numerical weather models\u202c",
        "\u202aMetrics for the Quality and Consistency of Ice Layer Annotations\u202c",
        "\u202aDevelopment and initial testing of XR-based fence diagrams for polar science\u202c",
        "\u202aPhotogrammetry and VR for comparing 2D and immersive linguistic data collection (student abstract)\u202c",
        "\u202aA Comparative Analysis of VR-Based and Real-World Human-Robot Collaboration for Small-Scale Joining\u202c",
        "\u202aLessons from a small-scale robot joining experiment in VR\u202c",
        "\u202aA 3D mixed reality visualization of network topology and activity results in better dyadic cyber team communication and cyber situational awareness\u202c",
        "\u202aDrones, Phones, and Stones: Initial Testing of a Role-Based, Computer-Supported Approach to Collaborative Cemetery Indexing\u202c",
        "\u202aMobile augmented reality system for object detection, alert, and safety\u202c",
        "\u202aIntegration of Reinforcement Learning and Unreal Engine for Enemy Containment via Autonomous Swarms\u202c",
        "\u202aUsing Moffat Profiles to Register Astronomical Images\u202c",
        "\u202aUser interactions in virtual data explorer\u202c",
        "\u202aInteractive stereoscopically perceivable multidimensional data visualizations for cybersecurity\u202c"
    ]
}